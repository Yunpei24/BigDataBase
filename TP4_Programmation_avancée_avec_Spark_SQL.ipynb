{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOP45UeQspgTRQ41G2I6oWn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yunpei24/BigDataBase/blob/main/TP4_Programmation_avanc%C3%A9e_avec_Spark_SQL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "Le but principal de ce notebook est de maîtriser <b>Spark SQL</b> et de pouvoir défnir des fonctions de fenêtre Spark et des fonctions Python enregistrées dans le registre Spark afin d'être utilisées dans les requêtes SQL.\n",
        "\n",
        "Le même jeu de données du précédent TP sera utilisé avec le même environnement d'exécution.\n"
      ],
      "metadata": {
        "id": "028oQK6oZSxd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialisation de l'environnement d'exécution"
      ],
      "metadata": {
        "id": "9z7VzgdtcHT7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installation du JDK"
      ],
      "metadata": {
        "id": "DDl4tHX3G3up"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VG2QZ2-puh60"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Téléchargement de l'archive du framework Apache Spark"
      ],
      "metadata": {
        "id": "IZEGyLLqHF1T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download Spark\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.3.1/spark-3.3.1-bin-hadoop3.tgz"
      ],
      "metadata": {
        "id": "8qPBj1B8tsrD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extraction de l'archive dans le dossier courant <mark>/content</mark>"
      ],
      "metadata": {
        "id": "DCHQaWogHUe-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip the file\n",
        "!tar xf spark-3.3.1-bin-hadoop3.tgz"
      ],
      "metadata": {
        "id": "seF5MAult-9S"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installation des modules Python <b>pyspark</b> et <b>findspark</b>"
      ],
      "metadata": {
        "id": "60GBDMzzHoFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pyspark\n",
        "!pip install -q findspark"
      ],
      "metadata": {
        "id": "g5LvxUKjsBsR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9813c303-cc67-4c77-e159-14a2546260f4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test de l'installation de pyspark"
      ],
      "metadata": {
        "id": "aHs729CucFMv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Y8u-WoOQZRcV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4efb8a3-922c-40ab-b7a2-298e13b2ce31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/spark-3.3.1-bin-hadoop3/python/pyspark\n",
            "/content/spark-3.3.1-bin-hadoop3/python/pyspark/python/pyspark\n",
            "/content/spark-3.3.1-bin-hadoop3/bin/pyspark\n"
          ]
        }
      ],
      "source": [
        "!find /content -name \"pyspark\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Création des variables d'environnement <mark>SPARK_HOME</mark> et <mark>JAVA_HOME</mark> pour situer respectivement les emplacements d'installation de Spark et Java "
      ],
      "metadata": {
        "id": "-eppwCZiIdsg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"SPARK_HOME\"] =  \"/content/spark-3.3.1-bin-hadoop3\" \n",
        "os.environ[\"JAVA_HOME\"] =\"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "metadata": {
        "id": "CSDjm_pZbWOW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importation des bibliothèques Spark SQL"
      ],
      "metadata": {
        "id": "HYkQctwUI4tE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "541d3a3c-4a20-41b6-9776-262e429052c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1a94a57-9e55-4012-a15b-e1331e985dce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "findspark.init() initialise les variables d'environnement pour spark\n"
          ]
        }
      ],
      "source": [
        "import findspark \n",
        "print(\"findspark.init() initialise les variables d'environnement pour spark\") \n",
        "findspark.init() \n",
        "\n",
        "# Pyspark session objects\n",
        "from pyspark.sql import SparkSession \n",
        "# Pyspark session configuration\n",
        "from pyspark import SparkConf  \n",
        "\n",
        "# Pyspark functions\n",
        "import pyspark.sql.functions as f\n",
        "from pyspark.sql import * \n",
        "\n",
        "# Pyspark SQL data types\n",
        "from pyspark.sql.types import *"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Définition de fonctions utiles pour la suite"
      ],
      "metadata": {
        "id": "DIpOBtsGKRtu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La fonction <mark>demarrer_spark</mark> permet d'initialiser une session <i>client</i> avec Spark"
      ],
      "metadata": {
        "id": "-yq3xQUUKcVF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "d1df52db-34b4-4298-b92d-f6df093f5715"
      },
      "outputs": [],
      "source": [
        "def demarrer_spark():\n",
        "  local = \"local[*]\"\n",
        "  appName = \"TP3\"\n",
        "  configLocale = SparkConf().setAppName(appName).setMaster(local).\\\n",
        "  set(\"spark.executor.memory\", \"100G\").\\\n",
        "  set(\"spark.driver.memory\",\"50G\").\\\n",
        "  set(\"spark.sql.catalogImplementation\",\"in-memory\").\\\n",
        "  set(\"spark.driver.maxResultSize\", \"10G\")\n",
        "  \n",
        "  spark = SparkSession.builder.config(conf = configLocale).getOrCreate()\n",
        "  sc = spark.sparkContext\n",
        "  sc.setLogLevel(\"ERROR\")\n",
        "  \n",
        "  # spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\",\"-1\")\n",
        "  # On ajuste l'environnement d'exécution des requêtes à la taille du cluster (4 coeurs)\n",
        "  # spark.conf.set(\"spark.sql.shuffle.partitions\",\"200\")    \n",
        "\n",
        "  print(\"session démarrée, son id est \", sc.applicationId)\n",
        "  return spark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Démarrage de la session"
      ],
      "metadata": {
        "id": "HvTT3nC6PDrw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark = demarrer_spark()"
      ],
      "metadata": {
        "id": "O_fkLyeXPPoY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa0362c5-c674-45a0-f5c1-706d8afcecc8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "session démarrée, son id est  local-1674566082656\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En vue de simplifier l'exécution des requêtes SQL, nous définissons la commande magique &#128526; <b><font color=\"blue\">%%sql</font></b> pour exécuter les requêtes plus facilement"
      ],
      "metadata": {
        "id": "N9WxdaTsrC0X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "202c9472-76de-4c92-98c1-6d55216aec7c"
      },
      "outputs": [],
      "source": [
        "from IPython.core.magic import (register_line_magic, register_cell_magic, register_line_cell_magic)\n",
        "\n",
        "def removeComments(query):\n",
        "  result = \"\"\n",
        "  for line in query.split('\\n'):\n",
        "    if not(line.strip().startswith(\"--\")):\n",
        "      result += line + \"\\n\"\n",
        "  return result\n",
        "\n",
        "@register_line_cell_magic\n",
        "def sql(line, cell=None):\n",
        "    \"To run a sql query. Use:  %%sql\"\n",
        "    val = cell if cell is not None else line\n",
        "    tabRequetes = removeComments(val).split(\";\")\n",
        "    resultat = None\n",
        "    est_une_requete = False\n",
        "    for r in tabRequetes:\n",
        "        r = r.strip()\n",
        "        if len(r) > 2:\n",
        "          resultat = spark.sql(r)\n",
        "          est_une_requete = r.lower().startswith('select') or r.lower().startswith('with')  \n",
        "    if(est_une_requete):\n",
        "      resultat.explain()\n",
        "      return display(resultat)\n",
        "    else:\n",
        "      return print('ok')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aed3e5e-d234-403b-a868-5a4a646a4955"
      },
      "source": [
        "De même, nous redéfinissons la fonction <b>display</b> pour un meilleur affichage des données manipulées."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "5548ea24-d1cd-44fa-8137-34222b6e847a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "085b6bc5-f2d2-4cbd-a268-af519de12df3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "display redéfini\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def display(df, n=10):\n",
        "  pd.set_option('max_columns', None)\n",
        "  pd.set_option('max_colwidth', None)\n",
        "  return df.limit(n).toPandas()\n",
        "\n",
        "print(\"display redéfini\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Programmation avancée avec <i>Spark SQL</i>\n",
        "Le travail consiste à utiliser des fonctions Python et <i>Spark SQL</i> avec le langage framework <i>pyspark</i> et d'effectuer des traitements distribués via des requêtes SQL. \n",
        "\n",
        "Vous devrez concevoir et écrire vous-même les requêtes à partir de la deuxième activité."
      ],
      "metadata": {
        "id": "fx6lv5EKQs-1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Activité 1 : utilisation de la clause <i>OVER</i> avec Spark SQL"
      ],
      "metadata": {
        "id": "4APT2Af_vWgj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Téléchargement du jeu de données de notre dernier TP, en l'occurence le fichier <u>purchases.txt</u>"
      ],
      "metadata": {
        "id": "u90yxGgIRcyi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -L -o 'purchases.txt' 'https://drive.google.com/u/0/uc?id=1NS-PSXW8bSNpzFH4XRbtmMnMGhXBdYy6&export=download&confirm=t'"
      ],
      "metadata": {
        "id": "Z1H5BOHtGgvK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36a8a407-a188-4a1d-abb1-6e4e32834764"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  201M  100  201M    0     0   124M      0  0:00:01  0:00:01 --:--:--  162M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Affichage des premiers lignes du fichier. Le format des enregistrement est le suivant:\n",
        "<table border='1'><tr>\n",
        "<td>Date</td><td>Heure</td><td>Magasin</td><td>Produit</td><td>Montant</td><td>Moyen_de_paiement</td>\n",
        "</tr></table>\n",
        "La tabulation <b>\\t</b> est utilisée comme séparateur de colonne ✅"
      ],
      "metadata": {
        "id": "bg4_s72GbrXI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!head -10  ./purchases.txt"
      ],
      "metadata": {
        "id": "sz1Hu-tgvz32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84cb521a-e688-4ef6-cdc7-4446865052aa"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2012-01-01\t09:00\tSan Jose\tMen's Clothing\t214.05\tAmex\n",
            "2012-01-01\t09:00\tFort Worth\tWomen's Clothing\t153.57\tVisa\n",
            "2012-01-01\t09:00\tSan Diego\tMusic\t66.08\tCash\n",
            "2012-01-01\t09:00\tPittsburgh\tPet Supplies\t493.51\tDiscover\n",
            "2012-01-01\t09:00\tOmaha\tChildren's Clothing\t235.63\tMasterCard\n",
            "2012-01-01\t09:00\tStockton\tMen's Clothing\t247.18\tMasterCard\n",
            "2012-01-01\t09:00\tAustin\tCameras\t379.6\tVisa\n",
            "2012-01-01\t09:00\tNew York\tConsumer Electronics\t296.8\tCash\n",
            "2012-01-01\t09:00\tCorpus Christi\tToys\t25.38\tDiscover\n",
            "2012-01-01\t09:00\tFort Worth\tToys\t213.88\tVisa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Création du dataframe Spark <mark>df</mark> à partir du jeu de données du fichier <u>purchases.txt</u> téléchargé"
      ],
      "metadata": {
        "id": "SEJsBGKGv5iJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "schemaTable = StructType([\n",
        "    StructField(\"Date\", DateType(), True),\n",
        "    StructField(\"Heure\", StringType(), True),\n",
        "    StructField(\"Magasin\", StringType(), True),\n",
        "    StructField(\"Produit\", StringType(), True),\n",
        "    StructField(\"Montant\", DoubleType(), True),\n",
        "    StructField(\"ModePaiement\", StringType(), True)\n",
        "    ])\n",
        "\n",
        "df = spark.read.load(\"purchases.txt\", format=\"csv\", sep=\"\\t\", schema=schemaTable, header=False)"
      ],
      "metadata": {
        "id": "lSkt9IYtv47X"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Affichage du dataframe"
      ],
      "metadata": {
        "id": "iTApIPq9zl9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(df)"
      ],
      "metadata": {
        "id": "hptmzOvKSpCu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "3dcccb53-8d91-4e89-af81-f95048d97f56"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Date  Heure         Magasin               Produit  Montant  \\\n",
              "0  2012-01-01  09:00        San Jose        Men's Clothing   214.05   \n",
              "1  2012-01-01  09:00      Fort Worth      Women's Clothing   153.57   \n",
              "2  2012-01-01  09:00       San Diego                 Music    66.08   \n",
              "3  2012-01-01  09:00      Pittsburgh          Pet Supplies   493.51   \n",
              "4  2012-01-01  09:00           Omaha   Children's Clothing   235.63   \n",
              "5  2012-01-01  09:00        Stockton        Men's Clothing   247.18   \n",
              "6  2012-01-01  09:00          Austin               Cameras   379.60   \n",
              "7  2012-01-01  09:00        New York  Consumer Electronics   296.80   \n",
              "8  2012-01-01  09:00  Corpus Christi                  Toys    25.38   \n",
              "9  2012-01-01  09:00      Fort Worth                  Toys   213.88   \n",
              "\n",
              "  ModePaiement  \n",
              "0         Amex  \n",
              "1         Visa  \n",
              "2         Cash  \n",
              "3     Discover  \n",
              "4   MasterCard  \n",
              "5   MasterCard  \n",
              "6         Visa  \n",
              "7         Cash  \n",
              "8     Discover  \n",
              "9         Visa  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-81b08a56-6da4-4154-acbe-deb38426d3eb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Heure</th>\n",
              "      <th>Magasin</th>\n",
              "      <th>Produit</th>\n",
              "      <th>Montant</th>\n",
              "      <th>ModePaiement</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2012-01-01</td>\n",
              "      <td>09:00</td>\n",
              "      <td>San Jose</td>\n",
              "      <td>Men's Clothing</td>\n",
              "      <td>214.05</td>\n",
              "      <td>Amex</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2012-01-01</td>\n",
              "      <td>09:00</td>\n",
              "      <td>Fort Worth</td>\n",
              "      <td>Women's Clothing</td>\n",
              "      <td>153.57</td>\n",
              "      <td>Visa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2012-01-01</td>\n",
              "      <td>09:00</td>\n",
              "      <td>San Diego</td>\n",
              "      <td>Music</td>\n",
              "      <td>66.08</td>\n",
              "      <td>Cash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2012-01-01</td>\n",
              "      <td>09:00</td>\n",
              "      <td>Pittsburgh</td>\n",
              "      <td>Pet Supplies</td>\n",
              "      <td>493.51</td>\n",
              "      <td>Discover</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2012-01-01</td>\n",
              "      <td>09:00</td>\n",
              "      <td>Omaha</td>\n",
              "      <td>Children's Clothing</td>\n",
              "      <td>235.63</td>\n",
              "      <td>MasterCard</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2012-01-01</td>\n",
              "      <td>09:00</td>\n",
              "      <td>Stockton</td>\n",
              "      <td>Men's Clothing</td>\n",
              "      <td>247.18</td>\n",
              "      <td>MasterCard</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2012-01-01</td>\n",
              "      <td>09:00</td>\n",
              "      <td>Austin</td>\n",
              "      <td>Cameras</td>\n",
              "      <td>379.60</td>\n",
              "      <td>Visa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2012-01-01</td>\n",
              "      <td>09:00</td>\n",
              "      <td>New York</td>\n",
              "      <td>Consumer Electronics</td>\n",
              "      <td>296.80</td>\n",
              "      <td>Cash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2012-01-01</td>\n",
              "      <td>09:00</td>\n",
              "      <td>Corpus Christi</td>\n",
              "      <td>Toys</td>\n",
              "      <td>25.38</td>\n",
              "      <td>Discover</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2012-01-01</td>\n",
              "      <td>09:00</td>\n",
              "      <td>Fort Worth</td>\n",
              "      <td>Toys</td>\n",
              "      <td>213.88</td>\n",
              "      <td>Visa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-81b08a56-6da4-4154-acbe-deb38426d3eb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-81b08a56-6da4-4154-acbe-deb38426d3eb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-81b08a56-6da4-4154-acbe-deb38426d3eb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Matérialisation du dataframe comme une vue SQL avec la vue <mark>purchases</mark> qui pointe sur lui."
      ],
      "metadata": {
        "id": "qHQ2kc-5S0xN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.createOrReplaceTempView('purchases')"
      ],
      "metadata": {
        "id": "xHMRJxopTdAo"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test de notre première requête SQL. <b>Que fait-elle ?</b>"
      ],
      "metadata": {
        "id": "FQkkIcjzTelx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "WITH meilleurProduitsParMagasin AS (SELECT magasin, produit, RANK() OVER(PARTITION BY magasin ORDER BY montant DESC) AS classement\n",
        "FROM purchases) SELECT magasin, produit FROM meilleurProduitsParMagasin WHERE classement <= 3 ORDER BY magasin ASC, classement DESC"
      ],
      "metadata": {
        "id": "5rbb8q6aznLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b>Que fait cette deuxième requête ?</b>\n",
        "N'hésitez pas ! Exécutez la &#128521;"
      ],
      "metadata": {
        "id": "yQ5Vvg4NaxNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "WITH cc AS (SELECT magasin, SUM(montant) AS total FROM purchases GROUP BY magasin), cc2 AS (SELECT magasin, total, ROW_NUMBER() over (ORDER BY total DESC) AS numero FROM cc) SELECT * FROM cc2 WHERE numero <= 5"
      ],
      "metadata": {
        "id": "ZEDuHKigajJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "WITH mp AS (select magasin, COUNT(Produit)) AS totalprod from purchases group by Produit), mp2 AS (SELECT magasin, totalprod, ROW_NUMBER() over (ORDER BY totalprod DESC) AS numero FROM mp) SELECT * FROM mp2 WHERE numero <= 3"
      ],
      "metadata": {
        "id": "mlc7s2AmELX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Activité 2\n",
        "Nous continuons à travailler avec la même vue <mark>purchases</mark>. <u>Le but est d’écrire vos propres requêtes</u>.\n",
        "<ol>\n",
        "<li>Donner le top 3 des magasins pour chaque mode de paiement.</li>\n",
        "<li>Donner le top 3 des magasins pour chaque produit.</li>\n",
        "</ol>"
      ],
      "metadata": {
        "id": "6Y1p3diBzHnO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Donner le top 3 des magasins pour chaque mode de paiement.\n",
        "%%sql \n",
        "WITH meilleurMagasinParModePaiement AS (SELECT magasin, ModePaiement, RANK() OVER(PARTITION BY magasin ORDER BY ModePaiement DESC) AS classement\n",
        "FROM purchases) SELECT magasin, ModePaiement FROM meilleurMagasinParModePaiement WHERE classement <= 3 ORDER BY magasin ASC, classement DESC"
      ],
      "metadata": {
        "id": "vOK9GpkBO0n2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Donner le top 3 des magasins pour chaque produit.\n",
        "%%sql\n",
        "WITH meilleurMagasinParProduit AS (SELECT magasin, Produit, RANK() OVER(PARTITION BY magasin ORDER BY Produit DESC) AS classement\n",
        "FROM purchases) SELECT magasin, Produit FROM meilleurMagasinParProduit WHERE classement <= 3 ORDER BY magasin ASC, classement DESC"
      ],
      "metadata": {
        "id": "sp6vCeQMO4oN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Activité 3 : utilisation de fonctions Python sous Spark SQL"
      ],
      "metadata": {
        "id": "pX7t7IUkIGsJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que fait la fonction suivante ?"
      ],
      "metadata": {
        "id": "lgCkPSxHIGsK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dayNames = ['', 'Lundi', 'Mardi', 'Mercredi', 'Jeudi', 'Vendredi', 'Samedi', 'Dimanche']\n",
        "  \n",
        "def weekDayName(dayID):\n",
        "  global dayNames\n",
        "  val = int(dayID)\n",
        "  if(1 <= val <= 7):\n",
        "    return dayNames[val]\n",
        "  else:\n",
        "    return \"Unknown\""
      ],
      "metadata": {
        "id": "O7COIe27IGsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enregistrement de la fonction dans le registre des fonctionnalités de Spark SQL"
      ],
      "metadata": {
        "id": "kfhx8ejMIGsK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.udf.register(\"weekDayName\", weekDayName, StringType())"
      ],
      "metadata": {
        "id": "Y1X7cY4UIGsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que fait la requête SQL ci-dessous ?"
      ],
      "metadata": {
        "id": "lUXKF1t8IGsL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "SELECT weekDayName(date_format(date, 'F')), SUM(montant) AS MontantTotal FROM purchases GROUP BY date_format(date, 'F')"
      ],
      "metadata": {
        "id": "1VtvHArHIGsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Activité 4\n",
        "Créer vos propres fonctions et requêtes SQL pour répondre aux questions suivantes.\n",
        "<ol>\n",
        "<li>Quel est le chiffre d'affaire réalisé par chaque magasin en francs CFA ? <b>Utiliser une fonction Python pour la conversion</b> <mark>Le taux de change n'est pas fixe. Il évolue dans le temps selon le contexte socio-économique.</mark> <u>Exemple:</u> <a href=\"https://www.google.com/search?client=firefox-b-d&q=dollar+to+cfa\">https://www.google.com/search?client=firefox-b-d&q=dollar+to+cfa</a></li>\n",
        "</ol>"
      ],
      "metadata": {
        "id": "afd3C9j8IGsM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<mark>Pour convertir des devises, vous pouvez utiliser le module Python <a href=\"https://pypi.org/project/CurrencyConverter/\">Currency Converter</a>.</mark> \n",
        "Dans les deux cellules qui suivent vous avez son installation et un exemple de conversion de 100 Euro en Dollar."
      ],
      "metadata": {
        "id": "KytxkVX7IGsa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install currencyconverter"
      ],
      "metadata": {
        "id": "04x0sUVwIGsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from currency_converter import CurrencyConverter\n",
        "converter = CurrencyConverter()\n",
        "converter.convert(100, 'EUR', 'USD')"
      ],
      "metadata": {
        "id": "aIM_lP6yIGsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Quel est le chiffre d'affaire réalisé par chaque magasin en francs CFA ?\n",
        "%%sql\n"
      ],
      "metadata": {
        "id": "ktv0_UaqIGsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Références\n",
        "**Window Functions** : \n",
        "https://spark.apache.org/docs/latest/sql-ref-syntax-qry-select-window.html\n",
        "\n",
        "**Supported Data Types with Spark SQL** : https://spark.apache.org/docs/latest/sql-ref-datatypes.html\n",
        "\n",
        "**Traitement de données massives avec Apache Spark** : http://b3d.bdpedia.fr/spark-batch.html\n",
        "\n",
        "**PySpark : Tout savoir sur la librairie Python** : https://datascientest.com/pyspark"
      ],
      "metadata": {
        "id": "2l-Rx110IGsb"
      }
    }
  ]
}