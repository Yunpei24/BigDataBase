{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yunpei24/BigDataBase/blob/main/Programmation_sous_MapReduceTP2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction à la programmation distribuée sous <i>MapReduce</i>\n",
        "L'objet principal de ce notebook est de maîtriser la programmation de traitement distribué sous <b>MapReduce</b>. \n",
        "Pour rappel, sous Hadoop, il ne revient pas au programmeur applicatif de mettre en œuvre les mécanismes de réplication, ni de gérer la traçabilité des grains et leur réaffectation. Ces tâches sont de la responsabilité du framework. \n",
        "\n",
        "Le programmeur applicatif a néanmoins le rôle de reformuler les algorithmes qu'il souhaite mettre en œuvre sur la plateforme distribuée suivant le mécanisme d’exécution <i>MapReduce</i>, un mécanisme d’exécution très populaire, présent dans plusieurs frameworks distribués.\n",
        "\n",
        "<i>MapReduce</i> décompose l’ensemble des opérations à réaliser en deux types de tâches <b>élémentaires</b> et <b>uniformes</b>, les <i>Map</i> et les <i>Reduce</i>. Chaque donnée passe d'abord par une tâche <i>Map</i> qui la transforme et éventuellement par une seconde tâche <i>Reduce</i>. \n",
        "\n",
        "Aucun ordre d'exécution particulier n'est attendu entre différentes tâches <i>Map</i> ou entre différentes tâches <i>Reduce</i>. Une ou plusieurs tâches <i>Map</i> et/ou <i>Reduce</i> peuvent être facilement assignées à chaque nœud de calcul. Un nœud de calcul peut correspondre à un ordinateur individuel ou à un cœur d'une unité centrale multi-cœur. Dans ce dernier cas, la mémoire vive et le stockage de masse de l’ordinateur sont partagés entre les cœurs.\n",
        "\n",
        "Le fonctionnement général de MapReduce est constitué des étapes suivantes:\n",
        "<ol>\n",
        "<li>L'ensemble de données à traiter est découpé en fragments (<i>chunks</i>).</li>\n",
        "<li>Chaque tâche <i>Map</i> est assignée à un nœud de calcul qui reçoit un ou plusieurs fragments que la tâche <i>Map</i> transforme en une séquence de paires \\[clé, valeur].</li>\n",
        "<li>Chaque tâche <i>Reduce</i> est associée à une ou plusieurs clés et est assignée à un nœud de calcul.</li>\n",
        "<li>Les paires (clé, valeur) produites par les <i>Map</i> sont groupées par clés et stockées sur les nœuds de calcul qui exécuteront les tâches <i>Reduce</i> respectives (étape shuffle).</li>\n",
        "<li>Chaque tâche <i>Reduce</i> combine, pour chaque clé qui lui est associée, les valeurs des paires [clé, valeur] avec cette clé ; les résultats sont stockés et constituent le résultat du traitement.</li>\n",
        "</ol>\n",
        "\n",
        "Le programmeur écrit les fonctions <i>Map</i> et <i>Reduce</i>, le framework se charge du reste comme illustré ci-dessous dans le décompte distribué de la fréquence de chaque mot d'un corpus.\n",
        "<!-- img width=\"70%\" src=\"https://res.cloudinary.com/talend/image/upload/q_auto,w_923,h_486/resources/seo-articles/seo-what-is-mapreduce_gj9ehi.webp\" -->\n",
        "\n",
        "<img width=\"70%\" src=\"https://www.nayaa.fr/bigdata/mr-execution-ex.png\">"
      ],
      "metadata": {
        "id": "-GxUGus3U-R6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Installation du Java Development Kit (JDK) \n",
        "Hadoop est écrit en Java et nécessite donc l'installation d'exécution de Java."
      ],
      "metadata": {
        "id": "qW7oVPy2wD_r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installation du JDK"
      ],
      "metadata": {
        "id": "9z7VzgdtcHT7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VG2QZ2-puh60"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Création de la variable d'environnement <JAVA_HOME> pour situer l'emplacement d'installationde Java "
      ],
      "metadata": {
        "id": "aHs729CucFMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "metadata": {
        "id": "6SJ7l69avQP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installation du framework Hadoop"
      ],
      "metadata": {
        "id": "zATmQRKXv6y5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Téléchargement depuis les archives de la fondation Apache"
      ],
      "metadata": {
        "id": "M2GpL7zccB-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://archive.apache.org/dist/hadoop/common/hadoop-3.3.0/hadoop-3.3.0.tar.gz"
      ],
      "metadata": {
        "id": "fIzgKOjjvVZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extraction de l'archive"
      ],
      "metadata": {
        "id": "d3tokPwWb_TU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xzvf hadoop-3.3.0.tar.gz"
      ],
      "metadata": {
        "id": "7Qsxg2nVvcql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copie du dossier extrait dans l'emplacement <user/local>"
      ],
      "metadata": {
        "id": "KMihsUJcb8mc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r hadoop-3.3.0/ /usr/local/"
      ],
      "metadata": {
        "id": "qiZu2f2MvfFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Programmation de tâches distribuées avec <i>MapReduce</i>"
      ],
      "metadata": {
        "id": "cPA7R0jj7Efs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Création d'un repertoire <myinput> pour contenir le jeu de données à tester durant cet exercice e d'un second pour les résultats du traitement distribué"
      ],
      "metadata": {
        "id": "zrgy3AhU6-ue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/myinput\n",
        "!mkdir -p ~/myoutput"
      ],
      "metadata": {
        "id": "CdW4R_x5vqoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Télachargement du jeu de données dans le fichier <u>purchases.txt</u>"
      ],
      "metadata": {
        "id": "0YYbaWQKbwgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -L -o 'purchases.txt' 'https://drive.google.com/u/0/uc?id=1NS-PSXW8bSNpzFH4XRbtmMnMGhXBdYy6&export=download&confirm=t'"
      ],
      "metadata": {
        "id": "Z1H5BOHtGgvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Déplacement du fichier <u>purchases.txt</u> dans le répertoire <myinput>"
      ],
      "metadata": {
        "id": "A4UhTIPWHalM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mv purchases.txt ~/myinput/purchases.txt"
      ],
      "metadata": {
        "id": "pxrmwexRvtra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vérification que les fichiers ont été bien copiés"
      ],
      "metadata": {
        "id": "TU3iICMSbt5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls ~/myinput"
      ],
      "metadata": {
        "id": "9pNAZrlXvxax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Affichage des premiers lignes du fichier. Le format des enregistrement est le suivant:\n",
        "<table border='1'><tr>\n",
        "<td>Date</td><td>Heure</td><td>Magasin</td><td>Produit</td><td>Montant</td><td>Moyen_de_paiement</td>\n",
        "</tr></table>\n",
        "La tabulation <b>\\t</b> est utilisée comme séparateur de colonne ✅"
      ],
      "metadata": {
        "id": "bg4_s72GbrXI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!head -10  ~/myinput/purchases.txt"
      ],
      "metadata": {
        "id": "sz1Hu-tgvz32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Activité 1"
      ],
      "metadata": {
        "id": "6Y1p3diBzHnO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le travail consiste à utiliser <i>MapReduce</i> avec le langage Python et effectuer un traitement distribué. Notre but est de déterminer le total des achats par magasin en exploitant les données du fichier <purchases.txt>.\n",
        "\n",
        "Vous devrez implémenter les fonctions <i>Map<i> et <i>Reduce</> du traitement."
      ],
      "metadata": {
        "id": "xKN45LMXblJb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Contenu de traitement dans la phase \\<map>. <h2>C'est à vous de le faire &#8987;</h2>"
      ],
      "metadata": {
        "id": "CwmgOTGZbap2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/python\n",
        "import sys\n",
        "# Mettez vos instructions ...\n",
        "for line in sys.stdin:\n",
        "  data = line.strip().split(\"\\t\")\n",
        "  if len(data) == 6:\n",
        "    date, time, store, item, amount, payment = data\n",
        "    print(store, \"\\t\", str(amount))"
      ],
      "metadata": {
        "id": "DORC5LGPzXTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sauvegarde du code de traitement de la phase <map> dans le fichier \"/content/map.py\""
      ],
      "metadata": {
        "id": "5FMoUYz0bJk6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# All cell codes are stored in a List variable \"In\"\n",
        "with open('/content/mapper.py', 'w') as f:\n",
        "  f.write(In[23]) \n",
        "f.close()"
      ],
      "metadata": {
        "id": "hF1orBgT3xZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attribution de permission d'accès et d'exécution sur le fichier <mapper.py>"
      ],
      "metadata": {
        "id": "kmdthu1tT9ah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod u+rwx /content/mapper.py"
      ],
      "metadata": {
        "id": "4o54WVW0UENR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test du traitement de la phase <map> sur quelques enregistrements"
      ],
      "metadata": {
        "id": "CaCsrIzRTHRV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!head -10 ~/myinput/purchases.txt | python3 /content/mapper.py"
      ],
      "metadata": {
        "id": "Kkc1LChRTIoj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Contenu de traitement de la phase \\<reduce>. <h2>C'est à vous de le faire aussi &#128521;</h2>"
      ],
      "metadata": {
        "id": "PMb1kR3ibXTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/python\n",
        "from operator import itemgetter\n",
        "import sys\n",
        "# Mettez vos instructions ...\n",
        "salesTotal = 0\n",
        "oldKey = None\n",
        "\n",
        "for line in sys.stdin:\n",
        "  data = line.strip().split(\"\\t\")\n",
        "  if len(data) != 2:\n",
        "    continue\n",
        "  \n",
        "  thisKey, thisSale = data\n",
        "  if oldKey and oldKey != thisKey:\n",
        "    print(oldKey, \"\\t\", str(salesTotal))\n",
        "    salesTotal = 0\n",
        "    \n",
        "  oldKey = thisKey\n",
        "  salesTotal += float (thisSale)\n",
        "\n",
        "if oldKey != None:\n",
        "  print(oldKey, \"\\t\", str(salesTotal))"
      ],
      "metadata": {
        "id": "47sDnvcIzfsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sauvegarde du code de traitement de la phase <reduce> dans le fichier \"/content/reduce.py\""
      ],
      "metadata": {
        "id": "l4-Y8tM7bO_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# All cell codes are stored in a List variable \"In\"\n",
        "with open('/content/reducer.py', 'w') as f:\n",
        "  f.write(In[37]) \n",
        "f.close()"
      ],
      "metadata": {
        "id": "xQBTPRMtz_M_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attribution de permission d'accès et d'exécution sur le fichier <reducer.py>"
      ],
      "metadata": {
        "id": "YmGnEPdz5YO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod u+rwx /content/reducer.py"
      ],
      "metadata": {
        "id": "QY6L7F6G5LJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test du traitement distribué sur quelques enregistrements"
      ],
      "metadata": {
        "id": "xrMCnnh7UZAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!head -50 ~/myinput/purchases.txt | python3 /content/mapper.py | sort | python3 /content/reducer.py"
      ],
      "metadata": {
        "id": "8aPj3aTbUfNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lancement d'un job entier. Le résultat est dans le dossier \"~/tryout\"."
      ],
      "metadata": {
        "id": "4qORR_Ag5WR1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r ~/myoutput\n",
        "!/usr/local/hadoop-3.3.0/bin/hadoop jar /usr/local/hadoop-3.3.0/share/hadoop/tools/lib/hadoop-streaming-3.3.0.jar -input ~/myinput -output ~/myoutput -file /content/mapper.py  -file /content/reducer.py  -mapper 'python mapper.py'  -reducer 'python reducer.py'"
      ],
      "metadata": {
        "id": "xGE52cAm5ZyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Affichage du contenu du dossier \"~/myoutput\"."
      ],
      "metadata": {
        "id": "0t76GHsU5ses"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls ~/myoutput"
      ],
      "metadata": {
        "id": "zRkWnc8D5ule"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Affichage d'un part du résultat contenu dans le fichier de sortie. On y trouve la fréquence de chaque mot contenu dans le corpus de documents."
      ],
      "metadata": {
        "id": "u6lEMkuYX6YI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!tail -n 30 ~/myoutput/part-00000"
      ],
      "metadata": {
        "id": "_dU_89Wr6PSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Activité 2\n",
        "Nous continuons à travailler avec le même fichier en entrées (purchases.txt), mais pour obtenir des résultats différents. <u>Le but est donc d’écrire vos propres Mappers et Reducers</u>.\n",
        "<ol>\n",
        "<li>Donner le nombre de paiement par mode de paiement.</li>\n",
        "<li>Quel est le chiffre d'affaire réalisé selon les jours de la semaine ?</li>\n",
        "<li>Quelle est la liste des magasins ?</li>\n",
        "<li>Quel est le nombre total des ventes et la valeur totale des ventes de tous magasins confondus ?</i>\n",
        "</ol>"
      ],
      "metadata": {
        "id": "TG0ZeTjD7GxQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Références\n",
        "**Réalisez des calculs distribués sur des données massives** : \n",
        "https://openclassrooms.com/fr/courses/4297166-realisez-des-calculs-distribues-sur-des-donnees-massives/4308656-familiarisez-vous-avec-hadoop\n",
        "\n",
        "**Hadoop : la nouvelle infrastructure de gestion de données** : https://juvenal-chokogoue.developpez.com/tutoriels/hadoop-fonctionnement/\n",
        "\n",
        "**MapReduce : comment l’utiliser pour le Big Data ?** : https://datascientest.com/mapreduce\n",
        "\n",
        "**Calcul distribué: Hadoop et MapReduce** : http://b3d.bdpedia.fr/calculdistr.html\n",
        "\n",
        "**Language Processing and Python** : https://www.nltk.org/book/ch01.html"
      ],
      "metadata": {
        "id": "gK7rOg_rZlUt"
      }
    }
  ]
}